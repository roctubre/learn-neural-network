{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Dense Neural Network / Fully connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Set training and test datasets\n",
    "train_data = datasets.MNIST(\"data\", train=True, download=True)\n",
    "test_data = datasets.MNIST(\"data\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(5000, 28, 28)\n",
      "(5000,)\n",
      "(5000, 28, 28)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy arrays\n",
    "train_features = np.array(train_data.data) / 255.\n",
    "train_labels = np.array(train_data.targets)\n",
    "valid_features = np.array(test_data.data[:len(test_data.data)//2])\n",
    "valid_labels = np.array(test_data.targets[:len(test_data.targets)//2])\n",
    "test_features = np.array(test_data.data[len(test_data.data)//2:])\n",
    "test_labels = np.array(test_data.targets[len(test_data.targets)//2:])\n",
    "\n",
    "print(train_features.shape)\n",
    "print(train_labels.shape)\n",
    "print(valid_features.shape)\n",
    "print(valid_labels.shape)\n",
    "print(test_features.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show a random image from train dataset\n",
    "\n",
    "height = 2\n",
    "width = 8\n",
    "\n",
    "f, axarr = plt.subplots(height, width, figsize=(20, 5))\n",
    "\n",
    "for y in range(width):\n",
    "    for x in range(height):\n",
    "        r_idx = random.randint(0, len(train_data.data))\n",
    "        axarr[x,y].set_title(int(train_data.targets[r_idx]))\n",
    "        axarr[x,y].imshow(train_data.data[r_idx], cmap='gray')\n",
    "        axarr[x,y].axis(\"off\")\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1, 28, 28)\n",
      "Epoch: 1 / 10 | Train Loss: 1.5289846803744633 | Time: 23.288\n",
      "Epoch: 2 / 10 | Train Loss: 0.6534404127796491 | Time: 23.750\n",
      "Epoch: 3 / 10 | Train Loss: 0.4753714478512605 | Time: 23.802\n",
      "Epoch: 4 / 10 | Train Loss: 0.41085817211618025 | Time: 24.286\n",
      "Epoch: 5 / 10 | Train Loss: 0.37643868766725064 | Time: 23.930\n",
      "Epoch: 6 / 10 | Train Loss: 0.35416442502290013 | Time: 23.927\n",
      "Epoch: 7 / 10 | Train Loss: 0.33800564703842007 | Time: 23.799\n",
      "Epoch: 8 / 10 | Train Loss: 0.3253327198512852 | Time: 23.666\n",
      "Epoch: 9 / 10 | Train Loss: 0.31484045039862396 | Time: 23.961\n",
      "Epoch: 10 / 10 | Train Loss: 0.3058432782130937 | Time: 23.908\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets \n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "num_workers = 0 \n",
    "n_epochs = 10\n",
    "\n",
    "# define tranformation pipeline\n",
    "transform = transforms.Compose([ \n",
    "    transforms.ToTensor()\n",
    "    #transforms.Normalize(0.5, 0.5) \n",
    "    ]) \n",
    "\n",
    "# Set training and test datasets\n",
    "train_data = datasets.MNIST(\"data\", train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers) \n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers) \n",
    "\n",
    "torch_model = nn.Sequential(\n",
    "    nn.Linear(28**2, 40),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(40, 10)\n",
    ")\n",
    "\n",
    "optimizer = optim.SGD(torch_model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next() \n",
    "images = images.numpy()\n",
    "print(images.shape)\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    start = time.time()\n",
    "    # TRAINING\n",
    "    torch_model.train()\n",
    "    for data, target in train_loader:\n",
    "        data = data.view(data.size(0), -1)\n",
    "        optimizer.zero_grad()\n",
    "        output = torch_model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    # VALIDATION\n",
    "    \n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    print(\"Epoch: {} / {} | Train Loss: {} | Time: {:.3f}\".format(\n",
    "        epoch, n_epochs, train_loss, time.time() - start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.26 %\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy\n",
    "import torch.nn.functional as F \n",
    "\n",
    "torch_model.eval()\n",
    "total = 0\n",
    "correct = 0\n",
    "for data, target in test_loader:\n",
    "    data = data.view(data.size(0), -1)\n",
    "    output = torch_model(data)\n",
    "    output = F.softmax(output, dim=1)\n",
    "    _, pred = torch.max(output, dim=1)\n",
    "    correct += torch.sum(target == pred).item()\n",
    "    total += len(target)\n",
    "\n",
    "print(\"Accuracy: {:.2f} %\".format((correct/total)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    sig = sigmoid(x)\n",
    "    return sig * (1 - sig)\n",
    "\n",
    "def sigmoid_derived(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x, x)\n",
    "\n",
    "def cross_entropy(x):\n",
    "    x = np.exp(x)\n",
    "    sums = np.sum(x, axis=1)\n",
    "    return x / sums.reshape((-1, 1))\n",
    "\n",
    "def cross_entropy_derived(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0.29692274 0.29692274 0.29692274 0.10923177]\n",
      " [0.0320586  0.08714432 0.23688282 0.64391426]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[0.5,0.5,0.5,-0.5],[1,2,3,4]]\n",
    "print(cross_entropy(x))\n",
    "np.sum(cross_entropy(x),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes):\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        self.input_weights = np.random.normal(0, 1.0, (input_nodes, hidden_nodes))\n",
    "        self.hidden_weights = np.random.normal(0, 1.0, (hidden_nodes, output_nodes))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        x = a batch of vectors (n, features)\n",
    "        \"\"\"\n",
    "        # FORWARD PROPAGATION\n",
    "        n_count = x.shape[0]\n",
    "        \n",
    "        \n",
    "        ## input to hidden\n",
    "        h_score = np.matmul(x, self.input_weights) # (n, hidden_nodes)\n",
    "        h_out = sigmoid(h_score) # (n, hidden_nodes)\n",
    "        \n",
    "        ## hidden to out\n",
    "        output_score = np.matmul(h_out, self.hidden_weights) # (n, output_nodes)\n",
    "        output = cross_entropy(output_score) # (n, output_nodes)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    def train(self, x, y, lr=0.01):\n",
    "        \"\"\"\n",
    "        x = a batch of vectors (n, features)\n",
    "        y = labels (one-hot-encoded) (n, outputs)\n",
    "        \"\"\"\n",
    "        # FORWARD PROPAGATION\n",
    "        n_count = x.shape[0]\n",
    "        \n",
    "        \n",
    "        ## input to hidden\n",
    "        h_score = np.matmul(x, self.input_weights) # (n, hidden_nodes)\n",
    "        h_out = sigmoid(h_score) # (n, hidden_nodes)\n",
    "        \n",
    "        ## hidden to out\n",
    "        output_score = np.matmul(h_out, self.hidden_weights) # (n, output_nodes)\n",
    "        output = cross_entropy(output_score) # (n, output_nodes)\n",
    "\n",
    "        error = -(1/n_count)*np.sum(np.log(output)*y) # (n, output_nodes)\n",
    "        \n",
    "        \n",
    "        # BACKWARD PROPAGATION\n",
    "        error_d = y / output\n",
    "        output_d = np.zeros((n_count, self.output_nodes, self.output_nodes))\n",
    "        for node_idx in range(self.output_nodes):\n",
    "            for s_idx in range(self.output_nodes):\n",
    "                if node_idx == s_idx:\n",
    "                    output_d[:, node_idx, s_idx] = output[:,s_idx]*(1 - output[:,s_idx]) * error_d[:,s_idx]\n",
    "                else:\n",
    "                    output_d[:, node_idx, s_idx] = -output[:,node_idx]*output[:,s_idx] * error_d[:,s_idx]\n",
    "        \n",
    "        h_o_gradient = np.zeros((self.hidden_nodes, self.output_nodes)) # (n, hidden_nodes, output_nodes)\n",
    "        for h_idx in range(self.hidden_nodes):\n",
    "            for out_idx in range(self.output_nodes):\n",
    "                h_o_gradient[h_idx, out_idx] = \\\n",
    "                    (np.sum(output_d[:, out_idx, :] * h_out[:, h_idx].reshape(-1,1))) / n_count\n",
    "         \n",
    "        # get hidden layer errors\n",
    "        hidden_d = np.zeros((n_count, self.hidden_nodes, self.output_nodes, self.output_nodes))\n",
    "        for h_idx in range(self.hidden_nodes):\n",
    "            for out_idx in range(self.output_nodes):\n",
    "                for s_idx in range(self.output_nodes):\n",
    "                    hidden_d[:, h_idx, node_idx, s_idx] = \\\n",
    "                        output_d[:, out_idx, s_idx] * self.hidden_weights[h_idx, out_idx] * \\\n",
    "                        sigmoid_derived(h_out[:,h_idx])\n",
    "                 \n",
    "        i_h_gradient = np.zeros((self.input_nodes, self.hidden_nodes))\n",
    "        for i_idx in range(self.input_nodes):\n",
    "            for h_idx in range(self.hidden_nodes):\n",
    "                i_h_gradient[i_idx, h_idx] = \\\n",
    "                    (np.sum(hidden_d[:, h_idx, -1] * x[:, i_idx].reshape(-1,1))) / n_count\n",
    "        \n",
    "        self.input_weights += i_h_gradient * lr\n",
    "        self.hidden_weights += h_o_gradient * lr\n",
    "\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 - ReLu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_relu:\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes):\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        self.input_weights = np.random.normal(0, 1.0, (input_nodes, hidden_nodes))\n",
    "        self.hidden_weights = np.random.normal(0, 1.0, (hidden_nodes, output_nodes))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        x = a batch of vectors (n, features)\n",
    "        \"\"\"\n",
    "        # FORWARD PROPAGATION\n",
    "        n_count = x.shape[0]\n",
    "        \n",
    "        \n",
    "        ## input to hidden\n",
    "        h_score = np.matmul(x, self.input_weights) # (n, hidden_nodes)\n",
    "        h_out = relu(h_score) # (n, hidden_nodes)\n",
    "        \n",
    "        ## hidden to out\n",
    "        output_score = np.matmul(h_out, self.hidden_weights) # (n, output_nodes)\n",
    "        output = cross_entropy(output_score) # (n, output_nodes)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    def train(self, x, y, lr=0.01, train=True):\n",
    "        \"\"\"\n",
    "        x = a batch of vectors (n, features)\n",
    "        y = labels (one-hot-encoded) (n, outputs)\n",
    "        \"\"\"\n",
    "        # FORWARD PROPAGATION\n",
    "        n_count = x.shape[0]\n",
    "        \n",
    "        \n",
    "        ## input to hidden\n",
    "        h_score = np.matmul(x, self.input_weights) # (n, hidden_nodes)\n",
    "        h_out = relu(h_score) # (n, hidden_nodes)\n",
    "        \n",
    "        ## hidden to out\n",
    "        output_score = np.matmul(h_out, self.hidden_weights) # (n, output_nodes)\n",
    "        output = cross_entropy(output_score) # (n, output_nodes)\n",
    "\n",
    "        error = -(1/n_count)*np.sum(np.log(output)*y) # (n, output_nodes)\n",
    "        \n",
    "        if not train:\n",
    "            return error\n",
    "        \n",
    "        # BACKWARD PROPAGATION\n",
    "        error_d = y / output\n",
    "        output_d = np.zeros((n_count, self.output_nodes, self.output_nodes))\n",
    "        for node_idx in range(self.output_nodes):\n",
    "            for s_idx in range(self.output_nodes):\n",
    "                if node_idx == s_idx:\n",
    "                    output_d[:, node_idx, s_idx] = output[:,s_idx]*(1 - output[:,s_idx]) * error_d[:,s_idx]\n",
    "                else:\n",
    "                    output_d[:, node_idx, s_idx] = -output[:,node_idx]*output[:,s_idx] * error_d[:,s_idx]\n",
    "        \n",
    "        h_o_gradient = np.zeros((self.hidden_nodes, self.output_nodes)) # (n, hidden_nodes, output_nodes)\n",
    "        for h_idx in range(self.hidden_nodes):\n",
    "            for out_idx in range(self.output_nodes):\n",
    "                h_o_gradient[h_idx, out_idx] = \\\n",
    "                    (np.sum(output_d[:, out_idx, :] * h_out[:, h_idx].reshape(-1,1))) / n_count\n",
    "         \n",
    "        # get hidden layer errors\n",
    "        hidden_d = np.zeros((n_count, self.hidden_nodes, self.output_nodes, self.output_nodes))\n",
    "        for h_idx in range(self.hidden_nodes):\n",
    "            for out_idx in range(self.output_nodes):\n",
    "                for s_idx in range(self.output_nodes):\n",
    "                    hidden_d[:, h_idx, node_idx, s_idx] = \\\n",
    "                        output_d[:, out_idx, s_idx] * self.hidden_weights[h_idx, out_idx] * \\\n",
    "                        h_out[:,h_idx]\n",
    "                 \n",
    "        i_h_gradient = np.zeros((self.input_nodes, self.hidden_nodes))\n",
    "        for i_idx in range(self.input_nodes):\n",
    "            for h_idx in range(self.hidden_nodes):\n",
    "                i_h_gradient[i_idx, h_idx] = \\\n",
    "                    (np.sum(hidden_d[:, h_idx, -1] * x[:, i_idx].reshape(-1,1))) / n_count\n",
    "        \n",
    "        self.input_weights += i_h_gradient * lr\n",
    "        self.hidden_weights += h_o_gradient * lr\n",
    "\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 - Added bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n",
      "[[1. 2. 3. 1.]\n",
      " [4. 5. 6. 1.]]\n"
     ]
    }
   ],
   "source": [
    "test = np.array([[1,2,3],[4,5,6]])\n",
    "new = np.ones((test.shape[0], test.shape[1]+1))\n",
    "new[:,:-1] = test\n",
    "print(new.shape)\n",
    "print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_bias:\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes):\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        self.input_weights = np.random.normal(0, 1.0, (input_nodes+1, hidden_nodes))\n",
    "        self.hidden_weights = np.random.normal(0, 1.0, (hidden_nodes+1, output_nodes))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        x = a batch of vectors (n, features)\n",
    "        \"\"\"\n",
    "        # FORWARD PROPAGATION\n",
    "        n_count = x.shape[0]\n",
    "        \n",
    "        ## add bias to input layer\n",
    "        new = np.ones((x.shape[0], x.shape[1]+1)) # (n, features+1)\n",
    "        new[:,:-1] = x\n",
    "        x = new\n",
    "        \n",
    "        ## input to hidden\n",
    "        h_score = np.matmul(x, self.input_weights) # (n, features+1) * (features+1, h_n) = (n, hidden_nodes)\n",
    "        h_out = relu(h_score) # (n, hidden_nodes)\n",
    "        \n",
    "        ## add bias to hidden layer\n",
    "        new = np.ones((h_out.shape[0], h_out.shape[1]+1)) # (n, hidden_nodes+1)\n",
    "        new[:,:-1] = h_out\n",
    "        h_out = new\n",
    "        \n",
    "        ## hidden to out\n",
    "        output_score = np.matmul(h_out, self.hidden_weights) # (n, output_nodes)\n",
    "        output = cross_entropy(output_score) # (n, output_nodes)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    def train(self, x, y, lr=0.01, train=True):\n",
    "        \"\"\"\n",
    "        x = a batch of vectors (n, features)\n",
    "        y = labels (one-hot-encoded) (n, outputs)\n",
    "        \"\"\"\n",
    "        # FORWARD PROPAGATION\n",
    "        n_count = x.shape[0]\n",
    "        \n",
    "        ## add bias to input layer\n",
    "        new = np.ones((x.shape[0], x.shape[1]+1)) # (n, features+1)\n",
    "        new[:,:-1] = x\n",
    "        x = new\n",
    "        \n",
    "        ## input to hidden\n",
    "        h_score = np.matmul(x, self.input_weights) # (n, hidden_nodes)\n",
    "        h_out = relu(h_score) # (n, hidden_nodes)\n",
    "        \n",
    "        ## add bias to hidden layer\n",
    "        new = np.ones((h_out.shape[0], h_out.shape[1]+1)) # (n, hidden_nodes+1)\n",
    "        new[:,:-1] = h_out\n",
    "        h_out = new\n",
    "        \n",
    "        ## hidden to out\n",
    "        output_score = np.matmul(h_out, self.hidden_weights) # (n, output_nodes)\n",
    "        output = cross_entropy(output_score) # (n, output_nodes)\n",
    "\n",
    "        error = -(1/n_count)*np.sum(np.log(output)*y) # (n, output_nodes)\n",
    "        \n",
    "        if not train:\n",
    "            return error\n",
    "        \n",
    "        # BACKWARD PROPAGATION\n",
    "        error_d = y / output\n",
    "        output_d = np.zeros((n_count, self.output_nodes, self.output_nodes))\n",
    "        for node_idx in range(self.output_nodes):\n",
    "            for s_idx in range(self.output_nodes):\n",
    "                if node_idx == s_idx:\n",
    "                    output_d[:, node_idx, s_idx] = output[:,s_idx]*(1 - output[:,s_idx]) * error_d[:,s_idx]\n",
    "                else:\n",
    "                    output_d[:, node_idx, s_idx] = -output[:,node_idx]*output[:,s_idx] * error_d[:,s_idx]\n",
    "        \n",
    "        h_o_gradient = np.zeros((self.hidden_nodes+1, self.output_nodes)) # (n, hidden_nodes, output_nodes)\n",
    "        for h_idx in range(self.hidden_nodes+1):\n",
    "            for out_idx in range(self.output_nodes):\n",
    "                h_o_gradient[h_idx, out_idx] = \\\n",
    "                    (np.sum(output_d[:, out_idx, :] * h_out[:, h_idx].reshape(-1,1))) / n_count\n",
    "         \n",
    "        # get hidden layer errors\n",
    "        hidden_d = np.zeros((n_count, self.hidden_nodes, self.output_nodes, self.output_nodes))\n",
    "        for h_idx in range(self.hidden_nodes):\n",
    "            for out_idx in range(self.output_nodes):\n",
    "                for s_idx in range(self.output_nodes):\n",
    "                    hidden_d[:, h_idx, node_idx, s_idx] = \\\n",
    "                        output_d[:, out_idx, s_idx] * self.hidden_weights[h_idx, out_idx] * \\\n",
    "                        h_out[:,h_idx]\n",
    "                 \n",
    "        i_h_gradient = np.zeros((self.input_nodes+1, self.hidden_nodes))\n",
    "        for i_idx in range(self.input_nodes+1):\n",
    "            for h_idx in range(self.hidden_nodes):\n",
    "                i_h_gradient[i_idx, h_idx] = \\\n",
    "                    (np.sum(hidden_d[:, h_idx, -1] * x[:, i_idx].reshape(-1,1))) / n_count\n",
    "        \n",
    "        self.input_weights += i_h_gradient * lr\n",
    "        self.hidden_weights += h_o_gradient * lr\n",
    "\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch: 5000 / 60000 | Train Error: 57.01709004 | Valid Error: 53.59286020\n",
      "Epoch: 1 | Batch: 10000 / 60000 | Train Error: 24.49927721 | Valid Error: 23.72398946\n",
      "Epoch: 1 | Batch: 15000 / 60000 | Train Error: 18.43392048 | Valid Error: 18.01935491\n",
      "Epoch: 1 | Batch: 20000 / 60000 | Train Error: 14.13415600 | Valid Error: 13.79410436\n",
      "Epoch: 1 | Batch: 25000 / 60000 | Train Error: 15.34709728 | Valid Error: 14.97028199\n",
      "Epoch: 1 | Batch: 30000 / 60000 | Train Error: 9.14593528 | Valid Error: 8.97243466\n",
      "Epoch: 1 | Batch: 35000 / 60000 | Train Error: 9.81944135 | Valid Error: 9.69219045\n",
      "Epoch: 1 | Batch: 40000 / 60000 | Train Error: 6.64580570 | Valid Error: 6.49909228\n",
      "Epoch: 1 | Batch: 45000 / 60000 | Train Error: 7.92708768 | Valid Error: 7.76239782\n",
      "Epoch: 1 | Batch: 50000 / 60000 | Train Error: 7.69971312 | Valid Error: 7.52696068\n",
      "Epoch: 1 | Batch: 55000 / 60000 | Train Error: 6.48457317 | Valid Error: 6.31623130\n",
      "Epoch: 1 | Batch: 60000 / 60000 | Train Error: 4.26530797 | Valid Error: 4.14988153\n",
      "Epoch: 2 | Batch: 5000 / 60000 | Train Error: 4.05701467 | Valid Error: 3.94871295\n",
      "Epoch: 2 | Batch: 10000 / 60000 | Train Error: 5.41679181 | Valid Error: 5.30449784\n",
      "Epoch: 2 | Batch: 15000 / 60000 | Train Error: 4.39019992 | Valid Error: 4.29324149\n",
      "Epoch: 2 | Batch: 20000 / 60000 | Train Error: 3.74995309 | Valid Error: 3.59244450\n",
      "Epoch: 2 | Batch: 25000 / 60000 | Train Error: 5.41347054 | Valid Error: 5.25035623\n",
      "Epoch: 2 | Batch: 30000 / 60000 | Train Error: 3.97254162 | Valid Error: 3.89749682\n",
      "Epoch: 2 | Batch: 35000 / 60000 | Train Error: 4.80973864 | Valid Error: 4.72485945\n",
      "Epoch: 2 | Batch: 40000 / 60000 | Train Error: 2.36078194 | Valid Error: 2.29208349\n",
      "Epoch: 2 | Batch: 45000 / 60000 | Train Error: 3.71045807 | Valid Error: 3.64319209\n",
      "Epoch: 2 | Batch: 50000 / 60000 | Train Error: 3.78386384 | Valid Error: 3.69771222\n",
      "Epoch: 2 | Batch: 55000 / 60000 | Train Error: 3.63617448 | Valid Error: 3.52115559\n",
      "Epoch: 2 | Batch: 60000 / 60000 | Train Error: 2.19762573 | Valid Error: 2.12697663\n",
      "Epoch: 3 | Batch: 5000 / 60000 | Train Error: 2.49175016 | Valid Error: 2.43253353\n",
      "Epoch: 3 | Batch: 10000 / 60000 | Train Error: 2.85379727 | Valid Error: 2.76532668\n",
      "Epoch: 3 | Batch: 15000 / 60000 | Train Error: 1.99068342 | Valid Error: 1.93627269\n",
      "Epoch: 3 | Batch: 20000 / 60000 | Train Error: 1.93611090 | Valid Error: 1.82936104\n",
      "Epoch: 3 | Batch: 25000 / 60000 | Train Error: 2.93550882 | Valid Error: 2.82486431\n",
      "Epoch: 3 | Batch: 30000 / 60000 | Train Error: 2.28537257 | Valid Error: 2.25269820\n",
      "Epoch: 3 | Batch: 35000 / 60000 | Train Error: 3.03398766 | Valid Error: 2.96435688\n",
      "Epoch: 3 | Batch: 40000 / 60000 | Train Error: 1.54771273 | Valid Error: 1.48220314\n",
      "Epoch: 3 | Batch: 45000 / 60000 | Train Error: 2.26765469 | Valid Error: 2.19357487\n",
      "Epoch: 3 | Batch: 50000 / 60000 | Train Error: 2.61255518 | Valid Error: 2.52493256\n",
      "Epoch: 3 | Batch: 55000 / 60000 | Train Error: 2.65660180 | Valid Error: 2.58025926\n",
      "Epoch: 3 | Batch: 60000 / 60000 | Train Error: 1.49536290 | Valid Error: 1.44524817\n",
      "Epoch: 4 | Batch: 5000 / 60000 | Train Error: 1.74397936 | Valid Error: 1.69166856\n",
      "Epoch: 4 | Batch: 10000 / 60000 | Train Error: 1.97643031 | Valid Error: 1.90104585\n",
      "Epoch: 4 | Batch: 15000 / 60000 | Train Error: 1.49313226 | Valid Error: 1.42306746\n",
      "Epoch: 4 | Batch: 20000 / 60000 | Train Error: 1.32275755 | Valid Error: 1.24942711\n",
      "Epoch: 4 | Batch: 25000 / 60000 | Train Error: 2.11007712 | Valid Error: 2.00494748\n",
      "Epoch: 4 | Batch: 30000 / 60000 | Train Error: 1.75219990 | Valid Error: 1.72098457\n",
      "Epoch: 4 | Batch: 35000 / 60000 | Train Error: 2.24262977 | Valid Error: 2.17971878\n",
      "Epoch: 4 | Batch: 40000 / 60000 | Train Error: 1.25823519 | Valid Error: 1.20333413\n",
      "Epoch: 4 | Batch: 45000 / 60000 | Train Error: 1.59773093 | Valid Error: 1.54098266\n",
      "Epoch: 4 | Batch: 50000 / 60000 | Train Error: 2.09435285 | Valid Error: 2.00633429\n",
      "Epoch: 4 | Batch: 55000 / 60000 | Train Error: 2.09603591 | Valid Error: 2.02641486\n",
      "Epoch: 4 | Batch: 60000 / 60000 | Train Error: 1.15661694 | Valid Error: 1.11930120\n"
     ]
    }
   ],
   "source": [
    "#model = NN(28**2, 40, 10)\n",
    "#model = NN_relu(28**2, 40, 10)\n",
    "model = NN_bias(28**2, 40, 10)\n",
    "\n",
    "batchsize = 100\n",
    "batchsize_valid = 100\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(1, epoch+1):\n",
    "    # Training\n",
    "    for idx in range(0, train_features.shape[0], batchsize):\n",
    "        features = train_features[idx:idx+batchsize].reshape((-1, 784))\n",
    "        labels = train_labels[idx:idx+batchsize]\n",
    "        labels_enc = np.zeros((batchsize, 10))\n",
    "        for l_idx in range(len(labels_enc)):\n",
    "            labels_enc[l_idx, labels[l_idx]] = 1\n",
    "\n",
    "        error = model.train(features, labels_enc)\n",
    "        #print(\"{} / {}\".format(idx, train_features.shape[0]) , error)\n",
    "        if idx % (batchsize * 50) == 0:\n",
    "            # Validation\n",
    "            error_valid = 0\n",
    "            for idx_v in range(0, len(valid_features), batchsize_valid):\n",
    "                features_valid = valid_features[idx_v:idx+batchsize_valid].reshape((-1,784))\n",
    "                labels_valid = valid_labels[idx_v:idx_v+batchsize_valid]\n",
    "                labels_enc_valid = np.zeros((batchsize_valid, 10))\n",
    "                error_valid += model.train(features, labels_enc, train=False)\n",
    "            \n",
    "            error_valid /= len(valid_features) / batchsize_valid\n",
    "            \n",
    "            print(\"Epoch: {} | Batch: {} / {} | Train Error: {:.8f} | Valid Error: {:.8f}\".format(\n",
    "                epoch, idx+(batchsize * 50), train_features.shape[0] , error, error_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ryan\\AppData\\Local\\conda\\conda\\envs\\deep-learning\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 34.3 %\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "nn_relu = 19.8 %\n",
    "nn_bias = 34.3 %\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "correct = 0\n",
    "\n",
    "for idx in range(0,len(test_features)):\n",
    "    features = test_features[idx].reshape((1,784))\n",
    "    result = np.argmax(model.predict(features))\n",
    "    if result == test_labels[idx]:\n",
    "        correct += 1\n",
    "    #print(\"Real: {} Prediction: {}\".format(test_labels[idx], result))\n",
    "print(\"Accuracy: {:.1f} %\".format((correct/len(test_features))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 0, 0, 0])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([1,2,3,-4,-5,-6])\n",
    "np.maximum(0, test, test)\n",
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
