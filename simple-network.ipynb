{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Dense Neural Network / Fully connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training and test datasets\n",
    "train_data = datasets.MNIST(\"data\", train=True, download=True)\n",
    "test_data = datasets.MNIST(\"data\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(5000, 28, 28)\n",
      "(5000,)\n",
      "(5000, 28, 28)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy arrays\n",
    "train_features = np.array(train_data.data) / 255.\n",
    "train_labels = np.array(train_data.targets)\n",
    "valid_features = np.array(test_data.data[:len(test_data.data)//2])\n",
    "valid_labels = np.array(test_data.targets[:len(test_data.targets)//2])\n",
    "test_features = np.array(test_data.data[len(test_data.data)//2:])\n",
    "test_labels = np.array(test_data.targets[len(test_data.targets)//2:])\n",
    "\n",
    "print(train_features.shape)\n",
    "print(train_labels.shape)\n",
    "print(valid_features.shape)\n",
    "print(valid_labels.shape)\n",
    "print(test_features.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show a random image from train dataset\n",
    "\n",
    "height = 2\n",
    "width = 8\n",
    "\n",
    "f, axarr = plt.subplots(height, width, figsize=(20, 5))\n",
    "\n",
    "for y in range(width):\n",
    "    for x in range(height):\n",
    "        r_idx = random.randint(0, len(train_data.data))\n",
    "        axarr[x,y].set_title(int(train_data.targets[r_idx]))\n",
    "        axarr[x,y].imshow(train_data.data[r_idx], cmap='gray')\n",
    "        axarr[x,y].axis(\"off\")\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1, 28, 28)\n",
      "Epoch: 1 / 1 | Train Loss: 1.4084401283661525 | Time: 9.328\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets \n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "num_workers = 0 \n",
    "n_epochs = 1\n",
    "\n",
    "# define tranformation pipeline\n",
    "transform = transforms.Compose([ \n",
    "    transforms.ToTensor()\n",
    "    #transforms.Normalize(0.5, 0.5) \n",
    "    ]) \n",
    "\n",
    "# Set training and test datasets\n",
    "train_data = datasets.MNIST(\"data\", train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers) \n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers) \n",
    "\n",
    "torch_model = nn.Sequential(\n",
    "    nn.Linear(28**2, 40, bias=False),\n",
    "    #nn.ReLU(),\n",
    "    nn.Linear(40, 10, bias=False)\n",
    ")\n",
    "\n",
    "optimizer = optim.SGD(torch_model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next() \n",
    "images = images.numpy()\n",
    "print(images.shape)\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    start = time.time()\n",
    "    # TRAINING\n",
    "    torch_model.train()\n",
    "    for data, target in train_loader:\n",
    "        data = data.view(data.size(0), -1)\n",
    "        optimizer.zero_grad()\n",
    "        output = torch_model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    # VALIDATION\n",
    "    \n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    print(\"Epoch: {} / {} | Train Loss: {} | Time: {:.3f}\".format(\n",
    "        epoch, n_epochs, train_loss, time.time() - start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.10 %\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy\n",
    "import torch.nn.functional as F \n",
    "\n",
    "torch_model.eval()\n",
    "total = 0\n",
    "correct = 0\n",
    "for data, target in test_loader:\n",
    "    data = data.view(data.size(0), -1)\n",
    "    output = torch_model(data)\n",
    "    output = F.softmax(output, dim=1)\n",
    "    _, pred = torch.max(output, dim=1)\n",
    "    correct += torch.sum(target == pred).item()\n",
    "    total += len(target)\n",
    "\n",
    "print(\"Accuracy: {:.2f} %\".format((correct/total)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    sig = sigmoid(x)\n",
    "    return sig * (1 - sig)\n",
    "\n",
    "def sigmoid_derived(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x, x)\n",
    "\n",
    "def cross_entropy(x):\n",
    "    x = np.exp(x)\n",
    "    sums = np.sum(x, axis=1)\n",
    "    return x / sums.reshape((-1, 1))\n",
    "\n",
    "def cross_entropy_derived(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.29692274 0.29692274 0.29692274 0.10923177]\n",
      " [0.0320586  0.08714432 0.23688282 0.64391426]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[0.5,0.5,0.5,-0.5],[1,2,3,4]]\n",
    "print(cross_entropy(x))\n",
    "np.sum(cross_entropy(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import minitorch as mt\n",
    "\n",
    "a = mt.Input_Node(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes):\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        self.input_weights = np.random.normal(0, 1.0, (input_nodes, hidden_nodes))\n",
    "        self.hidden_weights = np.random.normal(0, 1.0, (hidden_nodes, output_nodes))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        x = a batch of vectors (n, features)\n",
    "        \"\"\"\n",
    "        # FORWARD PROPAGATION\n",
    "        n_count = x.shape[0]\n",
    "        \n",
    "        \n",
    "        ## input to hidden\n",
    "        h_score = np.matmul(x, self.input_weights) # (n, hidden_nodes)\n",
    "        h_out = sigmoid(h_score) # (n, hidden_nodes)\n",
    "        \n",
    "        ## hidden to out\n",
    "        output_score = np.matmul(h_out, self.hidden_weights) # (n, output_nodes)\n",
    "        output = cross_entropy(output_score) # (n, output_nodes)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    def train(self, x, y, lr=0.01, train=True):\n",
    "        \"\"\"\n",
    "        x = a batch of vectors (n, features)\n",
    "        y = labels (one-hot-encoded) (n, outputs)\n",
    "        \"\"\"\n",
    "        # FORWARD PROPAGATION\n",
    "        n_count = x.shape[0]\n",
    "        \n",
    "        \n",
    "        ## input to hidden\n",
    "        h_score = np.matmul(x, self.input_weights) # (n, hidden_nodes)\n",
    "        h_out = sigmoid(h_score) # (n, hidden_nodes)\n",
    "        \n",
    "        ## hidden to out\n",
    "        output_score = np.matmul(h_out, self.hidden_weights) # (n, output_nodes)\n",
    "        output = cross_entropy(output_score) # (n, output_nodes)\n",
    "\n",
    "        error = -(1/n_count)*np.sum(np.log(output)*y) # (n, output_nodes)\n",
    "        \n",
    "        if not train:\n",
    "            return error\n",
    "        \n",
    "        # BACKWARD PROPAGATION\n",
    "        error_d = y / output\n",
    "        output_d = np.zeros((n_count, self.output_nodes, self.output_nodes))\n",
    "        for node_idx in range(self.output_nodes):\n",
    "            for s_idx in range(self.output_nodes):\n",
    "                if node_idx == s_idx:\n",
    "                    output_d[:, node_idx, s_idx] = output[:,s_idx]*(1 - output[:,s_idx]) * error_d[:,s_idx]\n",
    "                else:\n",
    "                    output_d[:, node_idx, s_idx] = -output[:,node_idx]*output[:,s_idx] * error_d[:,s_idx]\n",
    "        \n",
    "        h_o_gradient = np.zeros((self.hidden_nodes, self.output_nodes)) # (n, hidden_nodes, output_nodes)\n",
    "        for h_idx in range(self.hidden_nodes):\n",
    "            for out_idx in range(self.output_nodes):\n",
    "                h_o_gradient[h_idx, out_idx] = \\\n",
    "                    (np.sum(output_d[:, out_idx, :] * h_out[:, h_idx].reshape(-1,1))) / n_count\n",
    "         \n",
    "        # get hidden layer errors\n",
    "        hidden_d = np.zeros((n_count, self.hidden_nodes, self.output_nodes, self.output_nodes))\n",
    "        for h_idx in range(self.hidden_nodes):\n",
    "            for out_idx in range(self.output_nodes):\n",
    "                for s_idx in range(self.output_nodes):\n",
    "                    hidden_d[:, h_idx, node_idx, s_idx] = \\\n",
    "                        output_d[:, out_idx, s_idx] * self.hidden_weights[h_idx, out_idx] * \\\n",
    "                        sigmoid_derived(h_out[:,h_idx])\n",
    "                 \n",
    "        i_h_gradient = np.zeros((self.input_nodes, self.hidden_nodes))\n",
    "        for i_idx in range(self.input_nodes):\n",
    "            for h_idx in range(self.hidden_nodes):\n",
    "                i_h_gradient[i_idx, h_idx] = \\\n",
    "                    (np.sum(hidden_d[:, h_idx, -1] * x[:, i_idx].reshape(-1,1))) / n_count\n",
    "        \n",
    "        self.input_weights += i_h_gradient * lr\n",
    "        self.hidden_weights += h_o_gradient * lr\n",
    "\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 - ReLu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_relu:\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes):\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        self.input_weights = np.random.normal(0, 1.0, (input_nodes, hidden_nodes))\n",
    "        self.hidden_weights = np.random.normal(0, 1.0, (hidden_nodes, output_nodes))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        x = a batch of vectors (n, features)\n",
    "        \"\"\"\n",
    "        # FORWARD PROPAGATION\n",
    "        n_count = x.shape[0]\n",
    "        \n",
    "        \n",
    "        ## input to hidden\n",
    "        h_score = np.matmul(x, self.input_weights) # (n, hidden_nodes)\n",
    "        h_out = relu(h_score) # (n, hidden_nodes)\n",
    "        \n",
    "        ## hidden to out\n",
    "        output_score = np.matmul(h_out, self.hidden_weights) # (n, output_nodes)\n",
    "        output = cross_entropy(output_score) # (n, output_nodes)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    def train(self, x, y, lr=0.01, train=True):\n",
    "        \"\"\"\n",
    "        x = a batch of vectors (n, features)\n",
    "        y = labels (one-hot-encoded) (n, outputs)\n",
    "        \"\"\"\n",
    "        # FORWARD PROPAGATION\n",
    "        n_count = x.shape[0]\n",
    "        \n",
    "        \n",
    "        ## input to hidden\n",
    "        h_score = np.matmul(x, self.input_weights) # (n, hidden_nodes)\n",
    "        h_out = relu(h_score) # (n, hidden_nodes)\n",
    "        \n",
    "        ## hidden to out\n",
    "        output_score = np.matmul(h_out, self.hidden_weights) # (n, output_nodes)\n",
    "        output = cross_entropy(output_score) # (n, output_nodes)\n",
    "\n",
    "        error = -(1/n_count)*np.sum(np.log(output)*y) # (n, output_nodes)\n",
    "        \n",
    "        if not train:\n",
    "            return error\n",
    "        \n",
    "        # BACKWARD PROPAGATION\n",
    "        error_d = y / output\n",
    "        output_d = np.zeros((n_count, self.output_nodes, self.output_nodes))\n",
    "        for node_idx in range(self.output_nodes):\n",
    "            for s_idx in range(self.output_nodes):\n",
    "                if node_idx == s_idx:\n",
    "                    output_d[:, node_idx, s_idx] = output[:,s_idx]*(1 - output[:,s_idx]) * error_d[:,s_idx]\n",
    "                else:\n",
    "                    output_d[:, node_idx, s_idx] = -output[:,node_idx]*output[:,s_idx] * error_d[:,s_idx]\n",
    "        \n",
    "        h_o_gradient = np.zeros((self.hidden_nodes, self.output_nodes)) # (n, hidden_nodes, output_nodes)\n",
    "        for h_idx in range(self.hidden_nodes):\n",
    "            for out_idx in range(self.output_nodes):\n",
    "                h_o_gradient[h_idx, out_idx] = \\\n",
    "                    (np.sum(output_d[:, out_idx, :] * h_out[:, h_idx].reshape(-1,1))) / n_count\n",
    "         \n",
    "        # get hidden layer errors\n",
    "        hidden_d = np.zeros((n_count, self.hidden_nodes, self.output_nodes, self.output_nodes))\n",
    "        for h_idx in range(self.hidden_nodes):\n",
    "            for out_idx in range(self.output_nodes):\n",
    "                for s_idx in range(self.output_nodes):\n",
    "                    hidden_d[:, h_idx, node_idx, s_idx] = \\\n",
    "                        output_d[:, out_idx, s_idx] * self.hidden_weights[h_idx, out_idx] * \\\n",
    "                        h_out[:,h_idx]\n",
    "                 \n",
    "        i_h_gradient = np.zeros((self.input_nodes, self.hidden_nodes))\n",
    "        for i_idx in range(self.input_nodes):\n",
    "            for h_idx in range(self.hidden_nodes):\n",
    "                i_h_gradient[i_idx, h_idx] = \\\n",
    "                    (np.sum(hidden_d[:, h_idx, -1] * x[:, i_idx].reshape(-1,1))) / n_count\n",
    "        \n",
    "        self.input_weights += i_h_gradient * lr\n",
    "        self.hidden_weights += h_o_gradient * lr\n",
    "\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 - Added bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n",
      "[[1. 2. 3. 1.]\n",
      " [4. 5. 6. 1.]]\n"
     ]
    }
   ],
   "source": [
    "test = np.array([[1,2,3],[4,5,6]])\n",
    "new = np.ones((test.shape[0], test.shape[1]+1))\n",
    "new[:,:-1] = test\n",
    "print(new.shape)\n",
    "print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_bias:\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes):\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        self.input_weights = np.random.normal(0, 1.0, (input_nodes+1, hidden_nodes))\n",
    "        self.hidden_weights = np.random.normal(0, 1.0, (hidden_nodes+1, output_nodes))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        x = a batch of vectors (n, features)\n",
    "        \"\"\"\n",
    "        # FORWARD PROPAGATION\n",
    "        n_count = x.shape[0]\n",
    "        \n",
    "        ## add bias to input layer\n",
    "        new = np.ones((x.shape[0], x.shape[1]+1)) # (n, features+1)\n",
    "        new[:,:-1] = x\n",
    "        x = new\n",
    "        \n",
    "        ## input to hidden\n",
    "        h_score = np.matmul(x, self.input_weights) # (n, features+1) * (features+1, h_n) = (n, hidden_nodes)\n",
    "        h_out = relu(h_score) # (n, hidden_nodes)\n",
    "        \n",
    "        ## add bias to hidden layer\n",
    "        new = np.ones((h_out.shape[0], h_out.shape[1]+1)) # (n, hidden_nodes+1)\n",
    "        new[:,:-1] = h_out\n",
    "        h_out = new\n",
    "        \n",
    "        ## hidden to out\n",
    "        output_score = np.matmul(h_out, self.hidden_weights) # (n, output_nodes)\n",
    "        output = cross_entropy(output_score) # (n, output_nodes)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    def train(self, x, y, lr=0.01, train=True):\n",
    "        \"\"\"\n",
    "        x = a batch of vectors (n, features)\n",
    "        y = labels (one-hot-encoded) (n, outputs)\n",
    "        \"\"\"\n",
    "        # FORWARD PROPAGATION\n",
    "        n_count = x.shape[0]\n",
    "        \n",
    "        ## add bias to input layer\n",
    "        new = np.ones((x.shape[0], x.shape[1]+1)) # (n, features+1)\n",
    "        new[:,:-1] = x\n",
    "        x = new\n",
    "        \n",
    "        ## input to hidden\n",
    "        h_score = np.matmul(x, self.input_weights) # (n, hidden_nodes)\n",
    "        h_out = relu(h_score) # (n, hidden_nodes)\n",
    "        \n",
    "        ## add bias to hidden layer\n",
    "        new = np.ones((h_out.shape[0], h_out.shape[1]+1)) # (n, hidden_nodes+1)\n",
    "        new[:,:-1] = h_out\n",
    "        h_out = new\n",
    "        \n",
    "        ## hidden to out\n",
    "        output_score = np.matmul(h_out, self.hidden_weights) # (n, output_nodes)\n",
    "        output = cross_entropy(output_score) # (n, output_nodes)\n",
    "\n",
    "        error = -(1/n_count)*np.sum(np.log(output)*y) # (n, output_nodes)\n",
    "        \n",
    "        if not train:\n",
    "            return error\n",
    "        \n",
    "        # BACKWARD PROPAGATION\n",
    "        error_d = y / output\n",
    "        output_d = np.zeros((n_count, self.output_nodes, self.output_nodes))\n",
    "        for node_idx in range(self.output_nodes):\n",
    "            for s_idx in range(self.output_nodes):\n",
    "                if node_idx == s_idx:\n",
    "                    output_d[:, node_idx, s_idx] = output[:,s_idx]*(1 - output[:,s_idx]) * error_d[:,s_idx]\n",
    "                else:\n",
    "                    output_d[:, node_idx, s_idx] = -output[:,node_idx]*output[:,s_idx] * error_d[:,s_idx]\n",
    "        \n",
    "        h_o_gradient = np.zeros((self.hidden_nodes+1, self.output_nodes)) # (n, hidden_nodes, output_nodes)\n",
    "        for h_idx in range(self.hidden_nodes+1):\n",
    "            for out_idx in range(self.output_nodes):\n",
    "                h_o_gradient[h_idx, out_idx] = \\\n",
    "                    (np.sum(output_d[:, out_idx, :] * h_out[:, h_idx].reshape(-1,1))) / n_count\n",
    "         \n",
    "        # get hidden layer errors\n",
    "        hidden_d = np.zeros((n_count, self.hidden_nodes, self.output_nodes, self.output_nodes))\n",
    "        for h_idx in range(self.hidden_nodes):\n",
    "            for out_idx in range(self.output_nodes):\n",
    "                for s_idx in range(self.output_nodes):\n",
    "                    hidden_d[:, h_idx, node_idx, s_idx] = \\\n",
    "                        output_d[:, out_idx, s_idx] * self.hidden_weights[h_idx, out_idx] * \\\n",
    "                        h_out[:,h_idx]\n",
    "                 \n",
    "        i_h_gradient = np.zeros((self.input_nodes+1, self.hidden_nodes))\n",
    "        for i_idx in range(self.input_nodes+1):\n",
    "            for h_idx in range(self.hidden_nodes):\n",
    "                i_h_gradient[i_idx, h_idx] = \\\n",
    "                    (np.sum(hidden_d[:, h_idx, -1] * x[:, i_idx].reshape(-1,1))) / n_count\n",
    "        \n",
    "        self.input_weights += i_h_gradient * lr\n",
    "        self.hidden_weights += h_o_gradient * lr\n",
    "\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch: 5000 / 60000 | Train Error: 6.67766255 | Valid Error: 6.64869969\n",
      "Epoch: 1 | Batch: 10000 / 60000 | Train Error: 5.63744439 | Valid Error: 5.61708569\n",
      "Epoch: 1 | Batch: 15000 / 60000 | Train Error: 4.62516897 | Valid Error: 4.61367859\n",
      "Epoch: 1 | Batch: 20000 / 60000 | Train Error: 4.10173441 | Valid Error: 4.09383684\n",
      "Epoch: 1 | Batch: 25000 / 60000 | Train Error: 3.85606060 | Valid Error: 3.85028875\n",
      "Epoch: 1 | Batch: 30000 / 60000 | Train Error: 3.58484220 | Valid Error: 3.58128000\n",
      "Epoch: 1 | Batch: 35000 / 60000 | Train Error: 3.68546121 | Valid Error: 3.68204398\n",
      "Epoch: 1 | Batch: 40000 / 60000 | Train Error: 3.61682039 | Valid Error: 3.61147938\n",
      "Epoch: 1 | Batch: 45000 / 60000 | Train Error: 3.25099574 | Valid Error: 3.24827519\n",
      "Epoch: 1 | Batch: 50000 / 60000 | Train Error: 3.51161888 | Valid Error: 3.50887705\n",
      "Epoch: 1 | Batch: 55000 / 60000 | Train Error: 3.37002682 | Valid Error: 3.36720576\n",
      "Epoch: 1 | Batch: 60000 / 60000 | Train Error: 3.33644397 | Valid Error: 3.33403738\n"
     ]
    }
   ],
   "source": [
    "#model = NN(28**2, 40, 10)\n",
    "#model = NN_relu(28**2, 40, 10)\n",
    "model = NN(28**2, 40, 10)\n",
    "\n",
    "batchsize = 100\n",
    "batchsize_valid = 100\n",
    "epochs = 1\n",
    "\n",
    "for epoch in range(1, epoch+1):\n",
    "    # Training\n",
    "    for idx in range(0, train_features.shape[0], batchsize):\n",
    "        features = train_features[idx:idx+batchsize].reshape((-1, 784))\n",
    "        labels = train_labels[idx:idx+batchsize]\n",
    "        labels_enc = np.zeros((batchsize, 10))\n",
    "        for l_idx in range(len(labels_enc)):\n",
    "            labels_enc[l_idx, labels[l_idx]] = 1\n",
    "\n",
    "        error = model.train(features, labels_enc)\n",
    "        #print(\"{} / {}\".format(idx, train_features.shape[0]) , error)\n",
    "        if idx % (batchsize * 50) == 0:\n",
    "            # Validation\n",
    "            error_valid = 0\n",
    "            for idx_v in range(0, len(valid_features), batchsize_valid):\n",
    "                features_valid = valid_features[idx_v:idx+batchsize_valid].reshape((-1,784))\n",
    "                labels_valid = valid_labels[idx_v:idx_v+batchsize_valid]\n",
    "                labels_enc_valid = np.zeros((batchsize_valid, 10))\n",
    "                error_valid += model.train(features, labels_enc, train=False)\n",
    "            \n",
    "            error_valid /= len(valid_features) / batchsize_valid\n",
    "            \n",
    "            print(\"Epoch: {} | Batch: {} / {} | Train Error: {:.8f} | Valid Error: {:.8f}\".format(\n",
    "                epoch, idx+(batchsize * 50), train_features.shape[0] , error, error_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 16.0 %\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "nn_relu = 19.8 %\n",
    "nn_bias = 34.3 %\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "correct = 0\n",
    "\n",
    "for idx in range(0,len(test_features)):\n",
    "    features = test_features[idx].reshape((1,784))\n",
    "    result = np.argmax(model.predict(features))\n",
    "    if result == test_labels[idx]:\n",
    "        correct += 1\n",
    "    #print(\"Real: {} Prediction: {}\".format(test_labels[idx], result))\n",
    "print(\"Accuracy: {:.1f} %\".format((correct/len(test_features))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 0, 0, 0])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([1,2,3,-4,-5,-6])\n",
    "np.maximum(0, test, test)\n",
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
