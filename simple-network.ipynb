{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Dense Neural Network / Fully connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training and test datasets\n",
    "train_data = datasets.MNIST(\"data\", train=True, download=True)\n",
    "test_data = datasets.MNIST(\"data\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(5000, 28, 28)\n",
      "(5000,)\n",
      "(5000, 28, 28)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy arrays\n",
    "train_features = np.array(train_data.data) / 255.\n",
    "train_labels = np.array(train_data.targets)\n",
    "valid_features = np.array(test_data.data[:len(test_data.data)//2])\n",
    "valid_labels = np.array(test_data.targets[:len(test_data.targets)//2])\n",
    "test_features = np.array(test_data.data[len(test_data.data)//2:])\n",
    "test_labels = np.array(test_data.targets[len(test_data.targets)//2:])\n",
    "\n",
    "print(train_features.shape)\n",
    "print(train_labels.shape)\n",
    "print(valid_features.shape)\n",
    "print(valid_labels.shape)\n",
    "print(test_features.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show a random image from train dataset\n",
    "\n",
    "height = 2\n",
    "width = 8\n",
    "\n",
    "f, axarr = plt.subplots(height, width, figsize=(20, 5))\n",
    "\n",
    "for y in range(width):\n",
    "    for x in range(height):\n",
    "        r_idx = random.randint(0, len(train_data.data))\n",
    "        axarr[x,y].set_title(int(train_data.targets[r_idx]))\n",
    "        axarr[x,y].imshow(train_data.data[r_idx], cmap='gray')\n",
    "        axarr[x,y].axis(\"off\")\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    sig = sigmoid(x)\n",
    "    return sig * (1 - sig)\n",
    "\n",
    "def sigmoid_derived(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x, x)\n",
    "\n",
    "def cross_entropy(x):\n",
    "    x = np.exp(x)\n",
    "    sums = np.sum(x, axis=1)\n",
    "    return x / sums.reshape((-1, 1))\n",
    "\n",
    "def cross_entropy_derived(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0.29692274 0.29692274 0.29692274 0.10923177]\n",
      " [0.0320586  0.08714432 0.23688282 0.64391426]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[0.5,0.5,0.5,-0.5],[1,2,3,4]]\n",
    "print(cross_entropy(x))\n",
    "np.sum(cross_entropy(x),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes):\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        self.input_weights = np.random.normal(0, 1.0, (input_nodes, hidden_nodes))\n",
    "        self.hidden_weights = np.random.normal(0, 1.0, (hidden_nodes, output_nodes))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        x = a batch of vectors (n, features)\n",
    "        \"\"\"\n",
    "        # FORWARD PROPAGATION\n",
    "        n_count = x.shape[0]\n",
    "        \n",
    "        \n",
    "        ## input to hidden\n",
    "        h_score = np.matmul(x, self.input_weights) # (n, hidden_nodes)\n",
    "        h_out = sigmoid(h_score) # (n, hidden_nodes)\n",
    "        \n",
    "        ## hidden to out\n",
    "        output_score = np.matmul(h_out, self.hidden_weights) # (n, output_nodes)\n",
    "        output = cross_entropy(output_score) # (n, output_nodes)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    def train(self, x, y, lr=0.01):\n",
    "        \"\"\"\n",
    "        x = a batch of vectors (n, features)\n",
    "        y = labels (one-hot-encoded) (n, outputs)\n",
    "        \"\"\"\n",
    "        # FORWARD PROPAGATION\n",
    "        n_count = x.shape[0]\n",
    "        \n",
    "        \n",
    "        ## input to hidden\n",
    "        h_score = np.matmul(x, self.input_weights) # (n, hidden_nodes)\n",
    "        h_out = sigmoid(h_score) # (n, hidden_nodes)\n",
    "        \n",
    "        ## hidden to out\n",
    "        output_score = np.matmul(h_out, self.hidden_weights) # (n, output_nodes)\n",
    "        output = cross_entropy(output_score) # (n, output_nodes)\n",
    "\n",
    "        error = -(1/n_count)*np.sum(np.log(output)*y) # (n, output_nodes)\n",
    "        \n",
    "        \n",
    "        # BACKWARD PROPAGATION\n",
    "        error_d = y / output\n",
    "        output_d = np.zeros((n_count, self.output_nodes, self.output_nodes))\n",
    "        for node_idx in range(self.output_nodes):\n",
    "            for s_idx in range(self.output_nodes):\n",
    "                if node_idx == s_idx:\n",
    "                    output_d[:, node_idx, s_idx] = output[:,s_idx]*(1 - output[:,s_idx]) * error_d[:,s_idx]\n",
    "                else:\n",
    "                    output_d[:, node_idx, s_idx] = -output[:,node_idx]*output[:,s_idx] * error_d[:,s_idx]\n",
    "        \n",
    "        h_o_gradient = np.zeros((self.hidden_nodes, self.output_nodes)) # (n, hidden_nodes, output_nodes)\n",
    "        for h_idx in range(self.hidden_nodes):\n",
    "            for out_idx in range(self.output_nodes):\n",
    "                h_o_gradient[h_idx, out_idx] = \\\n",
    "                    (np.sum(output_d[:, out_idx, :] * h_out[:, h_idx].reshape(-1,1))) / n_count\n",
    "         \n",
    "        # get hidden layer errors\n",
    "        hidden_d = np.zeros((n_count, self.hidden_nodes, self.output_nodes, self.output_nodes))\n",
    "        for h_idx in range(self.hidden_nodes):\n",
    "            for out_idx in range(self.output_nodes):\n",
    "                for s_idx in range(self.output_nodes):\n",
    "                    hidden_d[:, h_idx, node_idx, s_idx] = \\\n",
    "                        output_d[:, out_idx, s_idx] * self.hidden_weights[h_idx, out_idx] * \\\n",
    "                        sigmoid_derived(h_out[:,h_idx])\n",
    "                 \n",
    "        i_h_gradient = np.zeros((self.input_nodes, self.hidden_nodes))\n",
    "        for i_idx in range(self.input_nodes):\n",
    "            for h_idx in range(self.hidden_nodes):\n",
    "                i_h_gradient[i_idx, h_idx] = \\\n",
    "                    (np.sum(hidden_d[:, h_idx, -1] * x[:, i_idx].reshape(-1,1))) / n_count\n",
    "        \n",
    "        self.input_weights += i_h_gradient * lr\n",
    "        self.hidden_weights += h_o_gradient * lr\n",
    "\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 - ReLu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_relu:\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes):\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        self.input_weights = np.random.normal(0, 1.0, (input_nodes, hidden_nodes))\n",
    "        self.hidden_weights = np.random.normal(0, 1.0, (hidden_nodes, output_nodes))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        x = a batch of vectors (n, features)\n",
    "        \"\"\"\n",
    "        # FORWARD PROPAGATION\n",
    "        n_count = x.shape[0]\n",
    "        \n",
    "        \n",
    "        ## input to hidden\n",
    "        h_score = np.matmul(x, self.input_weights) # (n, hidden_nodes)\n",
    "        h_out = relu(h_score) # (n, hidden_nodes)\n",
    "        \n",
    "        ## hidden to out\n",
    "        output_score = np.matmul(h_out, self.hidden_weights) # (n, output_nodes)\n",
    "        output = cross_entropy(output_score) # (n, output_nodes)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    def train(self, x, y, lr=0.01, train=True):\n",
    "        \"\"\"\n",
    "        x = a batch of vectors (n, features)\n",
    "        y = labels (one-hot-encoded) (n, outputs)\n",
    "        \"\"\"\n",
    "        # FORWARD PROPAGATION\n",
    "        n_count = x.shape[0]\n",
    "        \n",
    "        \n",
    "        ## input to hidden\n",
    "        h_score = np.matmul(x, self.input_weights) # (n, hidden_nodes)\n",
    "        h_out = relu(h_score) # (n, hidden_nodes)\n",
    "        \n",
    "        ## hidden to out\n",
    "        output_score = np.matmul(h_out, self.hidden_weights) # (n, output_nodes)\n",
    "        output = cross_entropy(output_score) # (n, output_nodes)\n",
    "\n",
    "        error = -(1/n_count)*np.sum(np.log(output)*y) # (n, output_nodes)\n",
    "        \n",
    "        if not train:\n",
    "            return error\n",
    "        \n",
    "        # BACKWARD PROPAGATION\n",
    "        error_d = y / output\n",
    "        output_d = np.zeros((n_count, self.output_nodes, self.output_nodes))\n",
    "        for node_idx in range(self.output_nodes):\n",
    "            for s_idx in range(self.output_nodes):\n",
    "                if node_idx == s_idx:\n",
    "                    output_d[:, node_idx, s_idx] = output[:,s_idx]*(1 - output[:,s_idx]) * error_d[:,s_idx]\n",
    "                else:\n",
    "                    output_d[:, node_idx, s_idx] = -output[:,node_idx]*output[:,s_idx] * error_d[:,s_idx]\n",
    "        \n",
    "        h_o_gradient = np.zeros((self.hidden_nodes, self.output_nodes)) # (n, hidden_nodes, output_nodes)\n",
    "        for h_idx in range(self.hidden_nodes):\n",
    "            for out_idx in range(self.output_nodes):\n",
    "                h_o_gradient[h_idx, out_idx] = \\\n",
    "                    (np.sum(output_d[:, out_idx, :] * h_out[:, h_idx].reshape(-1,1))) / n_count\n",
    "         \n",
    "        # get hidden layer errors\n",
    "        hidden_d = np.zeros((n_count, self.hidden_nodes, self.output_nodes, self.output_nodes))\n",
    "        for h_idx in range(self.hidden_nodes):\n",
    "            for out_idx in range(self.output_nodes):\n",
    "                for s_idx in range(self.output_nodes):\n",
    "                    hidden_d[:, h_idx, node_idx, s_idx] = \\\n",
    "                        output_d[:, out_idx, s_idx] * self.hidden_weights[h_idx, out_idx] * \\\n",
    "                        h_out[:,h_idx]\n",
    "                 \n",
    "        i_h_gradient = np.zeros((self.input_nodes, self.hidden_nodes))\n",
    "        for i_idx in range(self.input_nodes):\n",
    "            for h_idx in range(self.hidden_nodes):\n",
    "                i_h_gradient[i_idx, h_idx] = \\\n",
    "                    (np.sum(hidden_d[:, h_idx, -1] * x[:, i_idx].reshape(-1,1))) / n_count\n",
    "        \n",
    "        self.input_weights += i_h_gradient * lr\n",
    "        self.hidden_weights += h_o_gradient * lr\n",
    "\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 - Added bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n",
      "[[1. 2. 3. 1.]\n",
      " [4. 5. 6. 1.]]\n"
     ]
    }
   ],
   "source": [
    "test = np.array([[1,2,3],[4,5,6]])\n",
    "new = np.ones((test.shape[0], test.shape[1]+1))\n",
    "new[:,:-1] = test\n",
    "print(new.shape)\n",
    "print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_bias:\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes):\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        self.input_weights = np.random.normal(0, 1.0, (input_nodes+1, hidden_nodes))\n",
    "        self.hidden_weights = np.random.normal(0, 1.0, (hidden_nodes+1, output_nodes))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        x = a batch of vectors (n, features)\n",
    "        \"\"\"\n",
    "        # FORWARD PROPAGATION\n",
    "        n_count = x.shape[0]\n",
    "        \n",
    "        ## add bias to input layer\n",
    "        new = np.ones((x.shape[0], x.shape[1]+1)) # (n, features+1)\n",
    "        new[:,:-1] = x\n",
    "        x = new\n",
    "        \n",
    "        ## input to hidden\n",
    "        h_score = np.matmul(x, self.input_weights) # (n, features+1) * (features+1, h_n) = (n, hidden_nodes)\n",
    "        h_out = relu(h_score) # (n, hidden_nodes)\n",
    "        \n",
    "        ## add bias to hidden layer\n",
    "        new = np.ones((h_out.shape[0], h_out.shape[1]+1)) # (n, hidden_nodes+1)\n",
    "        new[:,:-1] = h_out\n",
    "        h_out = new\n",
    "        \n",
    "        ## hidden to out\n",
    "        output_score = np.matmul(h_out, self.hidden_weights) # (n, output_nodes)\n",
    "        output = cross_entropy(output_score) # (n, output_nodes)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    def train(self, x, y, lr=0.01, train=True):\n",
    "        \"\"\"\n",
    "        x = a batch of vectors (n, features)\n",
    "        y = labels (one-hot-encoded) (n, outputs)\n",
    "        \"\"\"\n",
    "        # FORWARD PROPAGATION\n",
    "        n_count = x.shape[0]\n",
    "        \n",
    "        ## add bias to input layer\n",
    "        new = np.ones((x.shape[0], x.shape[1]+1)) # (n, features+1)\n",
    "        new[:,:-1] = x\n",
    "        x = new\n",
    "        \n",
    "        ## input to hidden\n",
    "        h_score = np.matmul(x, self.input_weights) # (n, hidden_nodes)\n",
    "        h_out = relu(h_score) # (n, hidden_nodes)\n",
    "        \n",
    "        ## add bias to hidden layer\n",
    "        new = np.ones((h_out.shape[0], h_out.shape[1]+1)) # (n, hidden_nodes+1)\n",
    "        new[:,:-1] = h_out\n",
    "        h_out = new\n",
    "        \n",
    "        ## hidden to out\n",
    "        output_score = np.matmul(h_out, self.hidden_weights) # (n, output_nodes)\n",
    "        output = cross_entropy(output_score) # (n, output_nodes)\n",
    "\n",
    "        error = -(1/n_count)*np.sum(np.log(output)*y) # (n, output_nodes)\n",
    "        \n",
    "        if not train:\n",
    "            return error\n",
    "        \n",
    "        # BACKWARD PROPAGATION\n",
    "        error_d = y / output\n",
    "        output_d = np.zeros((n_count, self.output_nodes, self.output_nodes))\n",
    "        for node_idx in range(self.output_nodes):\n",
    "            for s_idx in range(self.output_nodes):\n",
    "                if node_idx == s_idx:\n",
    "                    output_d[:, node_idx, s_idx] = output[:,s_idx]*(1 - output[:,s_idx]) * error_d[:,s_idx]\n",
    "                else:\n",
    "                    output_d[:, node_idx, s_idx] = -output[:,node_idx]*output[:,s_idx] * error_d[:,s_idx]\n",
    "        \n",
    "        h_o_gradient = np.zeros((self.hidden_nodes+1, self.output_nodes)) # (n, hidden_nodes, output_nodes)\n",
    "        for h_idx in range(self.hidden_nodes+1):\n",
    "            for out_idx in range(self.output_nodes):\n",
    "                h_o_gradient[h_idx, out_idx] = \\\n",
    "                    (np.sum(output_d[:, out_idx, :] * h_out[:, h_idx].reshape(-1,1))) / n_count\n",
    "         \n",
    "        # get hidden layer errors\n",
    "        hidden_d = np.zeros((n_count, self.hidden_nodes, self.output_nodes, self.output_nodes))\n",
    "        for h_idx in range(self.hidden_nodes):\n",
    "            for out_idx in range(self.output_nodes):\n",
    "                for s_idx in range(self.output_nodes):\n",
    "                    hidden_d[:, h_idx, node_idx, s_idx] = \\\n",
    "                        output_d[:, out_idx, s_idx] * self.hidden_weights[h_idx, out_idx] * \\\n",
    "                        h_out[:,h_idx]\n",
    "                 \n",
    "        i_h_gradient = np.zeros((self.input_nodes+1, self.hidden_nodes))\n",
    "        for i_idx in range(self.input_nodes+1):\n",
    "            for h_idx in range(self.hidden_nodes):\n",
    "                i_h_gradient[i_idx, h_idx] = \\\n",
    "                    (np.sum(hidden_d[:, h_idx, -1] * x[:, i_idx].reshape(-1,1))) / n_count\n",
    "        \n",
    "        self.input_weights += i_h_gradient * lr\n",
    "        self.hidden_weights += h_o_gradient * lr\n",
    "\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch: 5000 / 60000 | Train Error: 57.01709004 | Valid Error: 53.59286020\n",
      "Epoch: 1 | Batch: 10000 / 60000 | Train Error: 24.49927721 | Valid Error: 23.72398946\n",
      "Epoch: 1 | Batch: 15000 / 60000 | Train Error: 18.43392048 | Valid Error: 18.01935491\n",
      "Epoch: 1 | Batch: 20000 / 60000 | Train Error: 14.13415600 | Valid Error: 13.79410436\n",
      "Epoch: 1 | Batch: 25000 / 60000 | Train Error: 15.34709728 | Valid Error: 14.97028199\n",
      "Epoch: 1 | Batch: 30000 / 60000 | Train Error: 9.14593528 | Valid Error: 8.97243466\n",
      "Epoch: 1 | Batch: 35000 / 60000 | Train Error: 9.81944135 | Valid Error: 9.69219045\n",
      "Epoch: 1 | Batch: 40000 / 60000 | Train Error: 6.64580570 | Valid Error: 6.49909228\n",
      "Epoch: 1 | Batch: 45000 / 60000 | Train Error: 7.92708768 | Valid Error: 7.76239782\n",
      "Epoch: 1 | Batch: 50000 / 60000 | Train Error: 7.69971312 | Valid Error: 7.52696068\n",
      "Epoch: 1 | Batch: 55000 / 60000 | Train Error: 6.48457317 | Valid Error: 6.31623130\n",
      "Epoch: 1 | Batch: 60000 / 60000 | Train Error: 4.26530797 | Valid Error: 4.14988153\n",
      "Epoch: 2 | Batch: 5000 / 60000 | Train Error: 4.05701467 | Valid Error: 3.94871295\n",
      "Epoch: 2 | Batch: 10000 / 60000 | Train Error: 5.41679181 | Valid Error: 5.30449784\n",
      "Epoch: 2 | Batch: 15000 / 60000 | Train Error: 4.39019992 | Valid Error: 4.29324149\n",
      "Epoch: 2 | Batch: 20000 / 60000 | Train Error: 3.74995309 | Valid Error: 3.59244450\n",
      "Epoch: 2 | Batch: 25000 / 60000 | Train Error: 5.41347054 | Valid Error: 5.25035623\n",
      "Epoch: 2 | Batch: 30000 / 60000 | Train Error: 3.97254162 | Valid Error: 3.89749682\n",
      "Epoch: 2 | Batch: 35000 / 60000 | Train Error: 4.80973864 | Valid Error: 4.72485945\n",
      "Epoch: 2 | Batch: 40000 / 60000 | Train Error: 2.36078194 | Valid Error: 2.29208349\n",
      "Epoch: 2 | Batch: 45000 / 60000 | Train Error: 3.71045807 | Valid Error: 3.64319209\n",
      "Epoch: 2 | Batch: 50000 / 60000 | Train Error: 3.78386384 | Valid Error: 3.69771222\n",
      "Epoch: 2 | Batch: 55000 / 60000 | Train Error: 3.63617448 | Valid Error: 3.52115559\n",
      "Epoch: 2 | Batch: 60000 / 60000 | Train Error: 2.19762573 | Valid Error: 2.12697663\n",
      "Epoch: 3 | Batch: 5000 / 60000 | Train Error: 2.49175016 | Valid Error: 2.43253353\n",
      "Epoch: 3 | Batch: 10000 / 60000 | Train Error: 2.85379727 | Valid Error: 2.76532668\n",
      "Epoch: 3 | Batch: 15000 / 60000 | Train Error: 1.99068342 | Valid Error: 1.93627269\n",
      "Epoch: 3 | Batch: 20000 / 60000 | Train Error: 1.93611090 | Valid Error: 1.82936104\n",
      "Epoch: 3 | Batch: 25000 / 60000 | Train Error: 2.93550882 | Valid Error: 2.82486431\n",
      "Epoch: 3 | Batch: 30000 / 60000 | Train Error: 2.28537257 | Valid Error: 2.25269820\n",
      "Epoch: 3 | Batch: 35000 / 60000 | Train Error: 3.03398766 | Valid Error: 2.96435688\n",
      "Epoch: 3 | Batch: 40000 / 60000 | Train Error: 1.54771273 | Valid Error: 1.48220314\n",
      "Epoch: 3 | Batch: 45000 / 60000 | Train Error: 2.26765469 | Valid Error: 2.19357487\n",
      "Epoch: 3 | Batch: 50000 / 60000 | Train Error: 2.61255518 | Valid Error: 2.52493256\n",
      "Epoch: 3 | Batch: 55000 / 60000 | Train Error: 2.65660180 | Valid Error: 2.58025926\n",
      "Epoch: 3 | Batch: 60000 / 60000 | Train Error: 1.49536290 | Valid Error: 1.44524817\n",
      "Epoch: 4 | Batch: 5000 / 60000 | Train Error: 1.74397936 | Valid Error: 1.69166856\n",
      "Epoch: 4 | Batch: 10000 / 60000 | Train Error: 1.97643031 | Valid Error: 1.90104585\n",
      "Epoch: 4 | Batch: 15000 / 60000 | Train Error: 1.49313226 | Valid Error: 1.42306746\n",
      "Epoch: 4 | Batch: 20000 / 60000 | Train Error: 1.32275755 | Valid Error: 1.24942711\n",
      "Epoch: 4 | Batch: 25000 / 60000 | Train Error: 2.11007712 | Valid Error: 2.00494748\n",
      "Epoch: 4 | Batch: 30000 / 60000 | Train Error: 1.75219990 | Valid Error: 1.72098457\n",
      "Epoch: 4 | Batch: 35000 / 60000 | Train Error: 2.24262977 | Valid Error: 2.17971878\n",
      "Epoch: 4 | Batch: 40000 / 60000 | Train Error: 1.25823519 | Valid Error: 1.20333413\n",
      "Epoch: 4 | Batch: 45000 / 60000 | Train Error: 1.59773093 | Valid Error: 1.54098266\n",
      "Epoch: 4 | Batch: 50000 / 60000 | Train Error: 2.09435285 | Valid Error: 2.00633429\n",
      "Epoch: 4 | Batch: 55000 / 60000 | Train Error: 2.09603591 | Valid Error: 2.02641486\n",
      "Epoch: 4 | Batch: 60000 / 60000 | Train Error: 1.15661694 | Valid Error: 1.11930120\n"
     ]
    }
   ],
   "source": [
    "#model = NN(28**2, 40, 10)\n",
    "#model = NN_relu(28**2, 40, 10)\n",
    "model = NN_bias(28**2, 40, 10)\n",
    "\n",
    "batchsize = 100\n",
    "batchsize_valid = 100\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(1, epoch+1):\n",
    "    # Training\n",
    "    for idx in range(0, train_features.shape[0], batchsize):\n",
    "        features = train_features[idx:idx+batchsize].reshape((-1, 784))\n",
    "        labels = train_labels[idx:idx+batchsize]\n",
    "        labels_enc = np.zeros((batchsize, 10))\n",
    "        for l_idx in range(len(labels_enc)):\n",
    "            labels_enc[l_idx, labels[l_idx]] = 1\n",
    "\n",
    "        error = model.train(features, labels_enc)\n",
    "        #print(\"{} / {}\".format(idx, train_features.shape[0]) , error)\n",
    "        if idx % (batchsize * 50) == 0:\n",
    "            # Validation\n",
    "            error_valid = 0\n",
    "            for idx_v in range(0, len(valid_features), batchsize_valid):\n",
    "                features_valid = valid_features[idx_v:idx+batchsize_valid].reshape((-1,784))\n",
    "                labels_valid = valid_labels[idx_v:idx_v+batchsize_valid]\n",
    "                labels_enc_valid = np.zeros((batchsize_valid, 10))\n",
    "                error_valid += model.train(features, labels_enc, train=False)\n",
    "            \n",
    "            error_valid /= len(valid_features) / batchsize_valid\n",
    "            \n",
    "            print(\"Epoch: {} | Batch: {} / {} | Train Error: {:.8f} | Valid Error: {:.8f}\".format(\n",
    "                epoch, idx+(batchsize * 50), train_features.shape[0] , error, error_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ryan\\AppData\\Local\\conda\\conda\\envs\\deep-learning\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 34.3 %\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "nn_relu = 19.8 %\n",
    "nn_bias = 34.3 %\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "correct = 0\n",
    "\n",
    "for idx in range(0,len(test_features)):\n",
    "    features = test_features[idx].reshape((1,784))\n",
    "    result = np.argmax(model.predict(features))\n",
    "    if result == test_labels[idx]:\n",
    "        correct += 1\n",
    "    #print(\"Real: {} Prediction: {}\".format(test_labels[idx], result))\n",
    "print(\"Accuracy: {:.1f} %\".format((correct/len(test_features))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 0, 0, 0])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([1,2,3,-4,-5,-6])\n",
    "np.maximum(0, test, test)\n",
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
